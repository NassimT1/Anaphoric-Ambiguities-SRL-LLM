{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7de38ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Using model: mrm8488/spanbert-finetuned-squadv2\n",
      "\n",
      "============================================================\n",
      "PREPROCESSING DATA\n",
      "============================================================\n",
      "Preprocessing complete. Created 267 pronoun instances.\n",
      "Class distribution:\n",
      "is_ambiguous_label\n",
      "0    0.573034\n",
      "1    0.426966\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "============================================================\n",
      "STEP 1: Creating Train/Validation/Test Split\n",
      "============================================================\n",
      "Train Set Size:      148 (55.4%)\n",
      "Validation Set Size: 38 (14.2%)\n",
      "Test Set Size:       81 (30.3%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mrm8488/spanbert-finetuned-squadv2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STEP 2: Extracting Features for Few-Shot Learning\n",
      "============================================================\n",
      "\n",
      "Processing train set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e742ef44476d4bbb997054a552c305de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example 0:\n",
      "  True label: Unambiguous\n",
      "  Num candidates: 4\n",
      "  Max prob: 0.962\n",
      "  Entropy: 0.140\n",
      "  Top2 ratio: 0.024\n",
      "  Prob gap: 0.939\n",
      "\n",
      "Example 1:\n",
      "  True label: Unambiguous\n",
      "  Num candidates: 8\n",
      "  Max prob: 0.909\n",
      "  Entropy: 0.181\n",
      "  Top2 ratio: 0.071\n",
      "  Prob gap: 0.845\n",
      "\n",
      "Example 2:\n",
      "  True label: Ambiguous\n",
      "  Num candidates: 20\n",
      "  Max prob: 0.846\n",
      "  Entropy: 0.165\n",
      "  Top2 ratio: 0.161\n",
      "  Prob gap: 0.710\n",
      "\n",
      "Processing validation set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "814b9a1e2b054805a9efb62b7c929b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing test set...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7ccfe9385e4cc392e717100ac1080b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting features:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING FEW-SHOT CLASSIFIER (WITH BALANCING)\n",
      "============================================================\n",
      "\n",
      "Logistic Regression:\n",
      "  Best Threshold: 0.461\n",
      "  Validation F1 (Ambiguous): 0.6500\n",
      "\n",
      "Random Forest:\n",
      "  Best Threshold: 0.401\n",
      "  Validation F1 (Ambiguous): 0.6829\n",
      "\n",
      "SVM (Linear Kernel):\n",
      "  Best Threshold: 0.425\n",
      "  Validation F1 (Ambiguous): 0.6500\n",
      "\n",
      "Naive Bayes:\n",
      "  Best Threshold: 0.232\n",
      "  Validation F1 (Ambiguous): 0.6667\n",
      "\n",
      "KNN (k=5):\n",
      "  Best Threshold: 0.600\n",
      "  Validation F1 (Ambiguous): 0.6471\n",
      "\n",
      "Gradient Boosting:\n",
      "  Best Threshold: 0.224\n",
      "  Validation F1 (Ambiguous): 0.7000\n",
      "\n",
      "AdaBoost:\n",
      "  Best Threshold: 0.454\n",
      "  Validation F1 (Ambiguous): 0.6154\n",
      "\n",
      "Selected Model: Gradient Boosting\n",
      "Optimized Threshold: 0.224\n",
      "\n",
      "============================================================\n",
      "STEP 3: Final Test Evaluation (Optimized)\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArIAAAJOCAYAAABLKeTiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIWUlEQVR4nO3deXhN5+L28TsjQkiUClFjS81DEUINQc1zWyqNGlpUzY4KNauEYx5KUfMxz9RQp1Sraq72UENqKkKDJpQIGd8/vNk/u0kq0bDytN/Pdbmu7LXXXuveC9vt2c9ayyEhISFBAAAAgGEcrQ4AAAAAPAmKLAAAAIxEkQUAAICRKLIAAAAwEkUWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjUWQBIJW4fwwAZCwUWSADOn78uAYOHKjatWurbNmyqlu3roYOHarLly8/tX1u27ZNderUUZkyZTR8+PB0227x4sU1Y8aMdNve4/ZVvHhxTZ48Odnn4+Pj9eqrr6p48eJav359mra9Zs0ajR8//rHrBQQEKCAgIE3bTsmYMWM0ZcoUSdL69ett7y/xV9myZdWoUSN9+umniouLS9O2r1y58kTHwWp+fn4KDAx87Hrnzp1T586dVaFCBdWrV08bNmx47GsCAwOTHOM//vLz80uPt5Eu/ngs3nrrLW3fvt3CRMCz52x1AAD2li1bpqCgIPn4+GjAgAF6/vnndenSJX322WfauXOnFi5cqFKlSqX7fkeNGqVChQpp3LhxypMnT7ptd9WqVfLy8kq37T2Oo6OjduzYof79+yd57vDhw7p+/foTbXf27NmqUqXKY9cbMWLEE23/jw4cOKCdO3fqiy++sFs+c+ZM5c6dWwkJCYqKitL333+v6dOn6/79++rbt2+67Nt00dHReu+995QnTx598skn2rFjhwYPHqxChQqpQoUKKb6uR48eateune3xrFmzdPLkSc2cOdO2zNXV9alm/ys++ugjde3aVVWqVNFzzz1ndRzgmaDIAhnI0aNHNXbsWPn7++ujjz6yLffx8VHdunXVunVrDR48WJs3b073fd+6dUvVq1eXj49Pum63fPny6bq9x6lYsaKOHDmin376KUnh37p1q0qUKKFTp049tf2/+OKL6bKd4OBgdejQQW5ubnbLS5Qoofz589se+/r66vLly1q5ciVF9v8LCQlRaGiohg4dKl9fX5UvX16rVq3SsWPH/rTIFihQQAUKFLA9zpkzp1xdXZ/5n+EnVbp0aZUqVUqzZ8/W0KFDrY4DPBNMLQAykPnz58vd3T3Z0cScOXMqMDBQr732mu7evWtbvm3bNrVu3VoVKlRQ9erVNXz4cN2+fdv2/IwZM1S/fn3t2bNHzZo1U+nSpdWgQQPbV60HDx5U8eLFJUmffPKJihcvritXrigwMDDJ16jJfR29dOlSNWzYUGXKlNGrr76qkSNH2uX749SC69eva/DgwapVq5bKli2r119/Xbt27bLbT/HixbVs2TJ99NFHqlKliipUqKDevXvr5s2bjz2GVapUUa5cuZJ8xRobG6udO3eqSZMmSV5z+vRp9ezZU1WrVlWpUqX06quv6uOPP9b9+/clPfwKNzQ0VBs2bLAdn/Xr16tkyZJas2aNatSooZo1a+rnn3+2m1qwZMmSJMfr8OHDKlGihKZPn57ie9izZ4/OnDmjpk2bPvb9SlKOHDnk4OBgt+zw4cPq0qWLKleurNKlS8vPz08zZsxQfHx8itt53GsSf/+3b9+u3r17q0KFCqpcubI++ugjRUZG2raTkJCgZcuWqUmTJipbtqzq16+vefPm2c0xPnLkiN5++22VK1dOVapU0aBBgxQeHm6X5/Tp0+rUqZMqVKigOnXqpPo/cN7e3sqUKZN27twpSTp06JAk/WmJTYvEvzMHDx60W/7HaSV+fn6aPn26xo8fL19fX5UtW1ZdunTRhQsX7F6XnseiefPmWrt2bZLXA39XFFkgg0hISNC3336ratWqKUuWLMmu07BhQ/Xs2VPZsmWT9PCrz379+qlcuXKaPn26PvjgA33xxRcKCAiwlTBJunHjhkaPHq0OHTpo7ty5yp8/vwIDA3Xu3DmVKlVKq1atkiS9/vrrWrVqlZ5//vlUZd66davGjx8vf39/zZ8/Xx988IE2bdqkjz/+ONn1b968qddff12HDh1Sv379NGPGDHl7e+uDDz5I8g/zlClTFB8fr8mTJ+vDDz/Unj17FBQU9NhMjo6OatCggXbs2GG3fP/+/Xrw4IHq1Kljt/z69evy9/dXVFSUxo0bp3nz5qlRo0ZaunSpFi1aJOn/vs6vVauW3fGJi4vTp59+qo8//lh9+/ZNMhobEBCgKlWqaPz48QoPD1dkZKQCAwNVunRp9ejRI8X3sHnzZpUvX1558+ZN8lx8fLxiY2MVGxuru3fv6ptvvtGmTZvk7+9vW+f06dPq2LGjPDw8NGXKFM2ePVsVK1bUzJkztXXr1mT3mZbXjBgxQt7e3po1a5beffddrVu3Tp9++qnt+cmTJ2vs2LGqVauWZs+erTfeeENTpkzRrFmzJD0szB07dlTmzJk1depUDRkyRIcOHVKHDh1sf27DwsL09ttv6/bt25owYYL69OmjiRMnKiwsLMXjlsjT01O9e/fWhg0bNGDAAPXv31+BgYHpVmTTYsmSJTp//ryCg4P18ccf68SJE3bzWtP7WNStW1dxcXH673//+8zeI2AlphYAGURERIQePHhg97Xxn7l9+7atJDw6L7NYsWLy9/fX+vXr1b59e0lSVFSUxo4dq2rVqkmSChUqpDp16ujrr79W586dbV+denl5pelr1IMHD8rb21v+/v5ydHRUlSpV5ObmpoiIiGTXX7hwocLDw7V9+3a98MILkqRatWqpY8eO+ve//62mTZvK0dHR9j6Cg4Ntr/3f//6XpJympHHjxlq2bJlOnDih0qVLS3o4cl23bl1lzpzZbt2QkBCVKFFC06ZNs/0HwdfXV/v379fhw4fVvXt3lSxZUq6ursqZM2eS49O9e3fVrl072RwODg4KCgpS8+bNNWHCBLm6uio8PFwLFiyQs3PKH78HDhxIduRYkurXr59kWZkyZfTOO+/YHp8+fVq+vr6aMGGC7XhWr15de/bs0eHDh9WsWbMk20jLa2rVqqVBgwZJkqpVq6Z9+/Zpz549GjBggH7//XctXLhQAQEB+vDDD23bCQ8P19GjRyVJkyZNUuHChTVnzhw5OTlJksqVK6cmTZpo3bp18vf316JFixQbG6t58+bZ5nsWLlxYb775ZorHLVF0dLRiYmLk4OCgzz//XD179lSnTp0e+7qnIXv27Jo1a5btfV66dEkzZsxQRESEPD090/1YuLm5qWjRotq/f7/atm377N4oYBGKLJBBJJaH1J59/sMPPyg6OjpJKalUqZK8vb118OBBW5GV7OeqJp58de/evb+UuWrVqlq1apVat26t1157TbVr11azZs2SfM2d6NChQ6pQoYKtxCZq3ry5Bg8erPPnz9tGNf9YGL28vBQVFZWqXK+88ory5Mmj7du3q3Tp0oqOjtaXX36pCRMmJFm3Ro0aqlGjhmJiYnThwgVdvHhRZ86cUXh4uDw8PB67r2LFiv3p8y+88IIGDRqkkSNHSnp4JYKCBQumuH5UVJR+++23FP9DM3v2bOXOnVuS9ODBA/3888+aPXu22rVrp1WrVilbtmxq2bKlWrZsqQcPHujSpUv65Zdf9NNPPykuLk4xMTHJbjctr0nu9yY0NFTSwz+XMTExSQp34ihkVFSUfvzxR3Xp0kUJCQmKjY21HaeiRYtq37598vf319GjR1W+fHm7k5bKlSunfPnypXjsErf/7rvv6ty5c5owYYIWLVqkefPmqXbt2vLy8tKqVavUuHFjFSlS5E+3k17KlCljK6jS//3di4qKUubMmZ/KsfD29taVK1ee4rsCMg6KLJBBeHh4KGvWrLp69WqK69y7d0/R0dHy8PCwzYPNlStXkvVy5cqlO3fu2C17dLpCYmn+q9dFbdy4seLj47V8+XLNnDlT06ZNk7e3twYMGJDsiOLt27eTLWiJ7+H3339PNm9i5tTmdXBwUMOGDbVjxw4NHDhQe/fulaOjo6pXr57k69jE6QvLli3TvXv3lDdvXpUtW1aZMmVK1b5Sc3Z4o0aNFBwcrLi4ONWoUeNP1008Bn88yStRsWLF7I5hpUqVVKxYMbVv315r1qxRp06ddP/+fY0ZM0abNm1SbGys8ufPrwoVKsjZ2TnFY5iW1/zZ782tW7ckPZzTndL7i4+P17x58zRv3rwkzyce95T+rCSW+JQsXrxYP/74o9avX69ixYqpSpUqev3119WzZ081b95cc+fO1auvvvqn20hPyR0r6eGfu6d1LLJkyZLk7z/wd0WRBTKQGjVq6ODBg3rw4EGyRWr9+vUaO3asli9frhw5ckh6OO+0aNGiduvduHEjyahnWjk4OCQZHU5uBLdp06Zq2rSp7ty5o2+//Vbz5s3TwIEDValSpSSX8cqRI0eyJ2zduHFD0sO5jemlcePGWrx4sY4fP65t27bptddek4uLS5L15s6dq0WLFmnkyJFq0KCB3N3dJT2cL5xePv74Y2XOnFlZsmTR0KFDNX/+/BTXTTwGj5b6xylRooQk6eLFi5KksWPH6osvvtDUqVPl6+trK8WJU0uS8ySvSU727NklSeHh4XajnteuXdMvv/yi0qVLy8HBQR07dkz2PzuJxc/T0zPZPyuJRTklx44dU7FixWwj5YmX4AoICNDcuXNVunRplStXLk3v6Y8Sv3H444lzkZGRypo1a6q3kzVr1qdyLH7//fd0/bsEZGSc7AVkIJ07d9atW7dsF8F/1G+//abPPvtMBQsWVPny5VWuXDm5urpqy5YtdusdOXJEV69eVcWKFf9SlqxZs9rm7Sb6/vvv7dbp27evevbsKUlyd3dXo0aN1KNHD8XFxSV7vdbKlSvr2LFjSW7ssHnzZuXOnftPv3JPq/Lly8vb21tbtmzR7t27U5xzevToUb344ot6/fXXbSU2LCxMISEhdkUlcSQtrb788ktt3rxZgYGBGjFihL799lutXLkyxfVdXV2VO3duXbt2LdX7+OGHHyQ9nPssPXxPPj4+qlevnq2QnjhxQuHh4SleteBJXpOcsmXLysXFJcmVKBYvXqw+ffooc+bMKlmypM6fP68yZcrYfr300kuaOXOm7UoAVatW1bFjx+xG0M+ePfvYm4K88MILunDhgn777Te7TFWrVpX0cAQ9Le8nOYlzqR/9Pbp9+7bOnTuX5u08jWNx7do1eXt7p/VtAUZiRBbIQMqXL68+ffpo6tSpOnfunFq1aiVPT0/9/PPPWrBggSIjIzV37lw5ODjIw8NDXbt21cyZM+Xi4qK6devqypUrmjZtml588UW1bt36L2WpU6eOli5dqiFDhuiNN96wZXh0vl/VqlU1YsQIjR8/XjVr1tTvv/+umTNnqlChQnr55ZeTbLNTp07avHmzOnXqpJ49e8rT01MbN27UgQMHFBQU9MRlMSUNGzbUkiVL5OHhkeLNDMqWLatZs2Zp7ty5Kl++vH755RfNmTNH0dHRdnNys2fPrpMnT+rQoUMqW7ZsqvYfHh6uESNGqHr16mrVqpUkqUGDBho/fryqV6+e4qh59erVk/ynIdGpU6dso3MJCQk6d+6cpk+frty5c9v2UbZsWW3fvl0rVqxQ0aJFdfr0ac2ePVsODg4pzjN+ktckJ2fOnOrQoYMWL14sV1dXVa1aVcePH9d//vMf9e/fX87Ozurfv7+6du2qAQMGqHnz5oqLi9OCBQv0448/6v3335ckvfPOO1q7dq26dOmiXr16KS4uTlOnTk12VP1RnTt31oYNG9S5c2f16NFDrq6uWrZsmQ4cOKA2bdpo3bp16tevn8aNG5fi1UEep3jx4sqbN69mzpwpd3d3OTo6au7cuU+0vfQ+Fnfu3NHZs2fVpUuXJ3pvgGkoskAG8/7776tkyZJatmyZgoODdevWLXl5ealmzZrq3r273QkevXr1Uq5cufSf//xHa9askYeHhxo2bKi+ffs+8T/SiapXr65BgwZp6dKl2rlzp0qVKqWZM2fa3fmoXbt2iomJ0cqVK7V8+XJlzpxZ1apV08CBA5P9RzZ37txasWKFJk2apLFjxyomJkYvv/yyZs2apbp16/6lvMlp3Lix5s+fr0aNGqVYkrt166aIiAgtWbJEn3zyifLmzasWLVrIwcFBc+bM0e3bt5UjRw517txZQUFB6tKlixYuXJiq/Y8aNUqRkZEaNWqUbdmwYcPUuHFjDRkyREuWLEn2xLgGDRpoy5Ytun79epJLoSWOgEuSs7OzPD095ePjoz59+thOTgsMDFRMTIymTp2q6Oho5c+fX++//77Onj2r3bt3J3tC4ZO8JiUDBw5Urly5tGLFCi1YsED58+fXkCFDbCcf1qhRQ/Pnz9fMmTPVu3dvubi4qFSpUlq4cKHtRDJPT0+tWLFCY8eOVWBgoLJmzap3331X27Zt+9N958uXT8uWLdPEiRNtJ5hVrFhRy5YtU7ly5VSyZElt3749xRMSU8PJyUnTp09XUFCQ+vfvr1y5cumdd97R+fPnk1wj9nHS+1js3btXLi4uKV5JA/i7cUj4q2d7AADSVUJCglq0aKEGDRrogw8+sDrO305CQsJfKrIZWUBAgF5++WW7OwMCf2fMkQWADMbBwUH/+te/tGLFCru7pCF9/F1L7I8//qgzZ86oa9euVkcBnhmKLABkQDVr1lTdunU1Z84cq6PAEMHBwRo+fPhjL1EG/J0wtQAAAABGYkQWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAj/a1uiDDv4C9WRwCAp6539wlWRwCApyrq2MxUrceILAAAAIxEkQUAAICRKLIAAAAwEkUWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjUWQBAABgJIosAAAAjESRBQAAgJEosgAAADASRRYAAABGosgCAADASBRZAAAAGIkiCwAAACNRZAEAAGAkiiwAAACMRJEFAACAkSiyAAAAMBJFFgAAAEaiyAIAAMBIFFkAAAAYiSILAAAAI1FkAQAAYCSKLAAAAIxEkQUAAICRKLIAAAAwEkUWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjUWQBAABgJIosAAAAjESRBQAAgJEosgAAADASRRYAAABGosgCAADASBRZAAAAGIkiCwAAACNRZAEAAGAkiiwAAACMRJEFAACAkSiyAAAAMBJFFgAAAEaiyAIAAMBIFFkAAAAYiSILAAAAI1FkAQAAYCSKLAAAAIxEkQUAAICRKLIAAAAwEkUWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjUWQBAABgJIosAAAAjESRBQAAgJEosgAAADASRRYAAABGosgCAADASBRZAAAAGIkiCwAAACNRZAEAAGAkiiwAAACMRJEFAACAkSiyAAAAMBJFFgAAAEaiyAIAAMBIFFkAAAAYiSILAAAAI1FkAQAAYCSKLAAAAIxEkQUAAICRKLIAAAAwEkUWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjUWQBAABgJIosAAAAjESRBQAAgJEosgAAADASRRYAAABGosgCAADASBRZAAAAGCnDFdlz584pLCzM6hgAAADI4Cwvst9//71atmwpSVq5cqWaNGmiunXr6ssvv7Q2GAAAADI0Z6sDTJo0SbVr11ZCQoLmzJmjcePGycPDQ5MmTVK9evWsjgcAAIAMyvIR2fPnz6tPnz46f/68bt68qcaNG6t27dq6cuWK1dEAAACQgVleZJ2cnBQZGalvvvlG5cuXl6urq0JDQ5UtWzarowEAACADs3xqQb169fT2228rNDRUQ4cO1dmzZ/XBBx+oadOmVkcDAABABmZ5kR02bJg2btyoLFmyqHHjxrp48aLatWunDh06WB0NAAAAGZjlRdbJyUlt2rSxPS5UqJA6depkYSIAAACYwPIi6+fnJwcHh2Sf27Vr1zNOAwAAAFNYXmR79epl9zg8PFzr1q3TG2+8YVEiAAAAmMDyItuqVasky+rXr6/+/fszxQAAAAApsvzyW8nx9vbWxYsXrY4BAACADMzyEdnDhw/bPY6JidGOHTtUqFAhawIBAADACJYX2YCAALvHjo6OKlq0qEaMGGFRIgAAAJjA8iJ7+vRpqyMAAADAQJYXWUn69ddftWXLFoWGhur5559X06ZNVaBAAatjAQAAIAOz/GSv48ePq0mTJtq5c6du376tXbt2qXnz5jp69KjV0QAAAJCBWT4iO2HCBPXp08fulrSLFy/WxIkTtWLFCguTAQAAICOzfET2zJkzat++vd2y9u3bKyQkxKJEAAAAMIHlRTZLliy6du2a3bJr164pR44cFiUCAACACSwvso0bN1avXr20d+9eXbhwQV9//bV69+6txo0bWx0NAAAAGZjlc2T79Omj8PBw9ejRQzExMcqUKZPatGmjnj17Wh0NAAAAGZhDQkJCgtUhJCk6Olq3b99Wrly55ODg8ETbmHfwl3ROBQAZT+/uE6yOAABPVdSxmalaz/IR2Y0bN6b4XMuWLZ9ZDgAAAJjF8iI7ffp0u8e3b99WVFSUXnnlFYosAAAAUmR5kd29e7fd44SEBM2bN0+3bt2yJhAAAACMYPlVC/7IwcFBXbp00aZNm6yOAgAAgAwswxVZSbpw4cITn/AFAACAfwbLpxYEBATYldaYmBidOXNGzZs3tzAVAAAAMjrLi6yPj4/dY0dHR3Xs2FH16tWzKBEAAABMYHmR5cYHAAAAeBKWF9k/Ti1I5OLiopw5c6pOnTrcrhYAAABJWH6yV7ly5XTq1CmVKVNGjRs3Vvny5XXmzBnlzJlTuXLl0tixY7V06VKrYwIAACCDsXxE9vvvv9fs2bNVqVIl27K6detqwoQJmjBhglq0aKE+ffooICDAwpQAAADIaCwvsiEhIapYsaLdsjJlyujkyZOSpJdfflk3btywIhqQxL3fb2n56L56rUs/FShRTpL030XTdeKbL+To5GRbr3b7bipXp4lVMQHgidSqXExjejVX8cJ5dO9+jDZ8eUxDpm7U/QcxtnV8yhbWjrm95Vm1n4VJgYcsL7IvvPCC1q1bpzfeeMO2bMuWLcqXL58k6aefflLu3LmtigfYhIb8pO1zJ+jW9at2y389f0b1O/VR6VdfsygZAPx1uTyzacP07uodtErLPj+kPM+5a8usnvpXp/r6+NNtkqQOLapq4sDXlTmTi8VpgYcsL7IDBw7U+++/r3Xr1snb21tXr17V6dOnNX36dJ06dUpvv/22PvroI6tj4h/uxN6d2rd+iWq1fVefzwqyLY+NidbNKxflVbiYhekA4K+7GXFXBeoO1t17DyRJOXNkVeZMzroZcVeSNGfk2ypeOI8+/nSbxg9obWVUwMbyIuvr66utW7dqy5Yt+vXXX1WnTh1NnTpVefLk0a+//qrly5erRIkSVsfEP1zhMpVU0reuHJ2c7IrsjUvnFRcXq33rlyg05IQyZcmq0rUaqkrjN+TgaPm5lACQJokl9uyOMfLO46lvvz+rJZsOSJJGz/pcoddv6dVXXrIyImDH8iIrSfnz59f777+fZLmXl5e8vLwsSATYy+qRM9nlD6Ii9cLLZVXxtZZq2mOIrv9yVpumj5KDg4OqNHnzGacEgPRRusVoeWZ308Kx72j5xC5q2XO2Qq/fsjoWkIRlRbZZs2basmWL/Pz8kr2OrCTt2rXrGacC0qZQ6VdUqPQrtsd5i76siq+10pmDX1NkARjr/oMYXbtxW0OnbdLe/wyUh3sW3boTZXUsIAnLimzXrl0lSb169bIqAvCX/Xx0n+7djlA5v6a2ZXGxMXJ2zWRhKgBIu6rlCuvTEf6q/GawYmLjJEmZXJ31IDpGkVHRFqcDkmfpiKwktWrVyrYsIiJCnp6eVkUC0i4hQV8tnyOPPN4qULK8rp09pe93blSd9t2sTgYAaXI8JFRumV31cZ8WGjptk/Lmzq7gfq20aON+W7EFMhrL58hGRkYqODhYW7ZsUXR0tLJkyaJ27dqpb9++cnV1tToe8KdeqlRDddrf0peLZ+hO+A1l9cgp31YBKlm9ntXRACBNIqOi1bznLE34Vxv9sitYv9+N0oqthxU8b4fV0YAUOSQkJCRYGWDYsGEKCQlR7969lTdvXl2+fFnTpk2Tj4+PBg0alKZtzTv4y1NKCQAZR+/uE6yOAABPVdSxmalaz/IR2a+++kqbN29WzpwPzwovUqSIihcvrtdffz3NRRYAAAD/HJZf6DJLlixyeuTWnpLk5uam+Ph4ixIBAADABJYV2atXr+rq1atq2bKl+vXrp5CQEEVGRurChQsKDAxUx44drYoGAAAAA1g2tSDx+rGJU3SbN29uu55sQkKCvvrqK9slugAAAIA/sqzIcrMDAAAA/BWWFVlvb2/bz7Gxsbp58ybzYgEAAJBqll+1YO3atRo9erRiYmJsyxISEuTg4KBTp05ZmAwAAAAZmeVFdurUqRo4cKBq164tR0fLL6IAAAAAQ1heZKOjo+Xv70+JBQAAQJpY3h6bN2+uFStWWB0DAAAAhrF8RLZevXrq0qWLpk2bJnd3d7vnuLIBAAAAUmJ5kR0xYoQaNmyoatWqJbnDFwAAAJASy4vs9evXNWnSJKtjAAAAwDCWz5H18fHRsWPHrI4BAAAAw1g+Iuvt7a3OnTvLx8dHnp6eds8FBwdblAoAAAAZneVF9t69e2rYsKHVMQAAAGAYy4sso64AAAB4EpYX2ejoaG3ZskVhYWGKj4+XJMXExCgkJESzZ8+2OB0AAAAyKsuL7JAhQ7R37155enoqJiZGbm5u+vnnn9WyZUurowEAACADs7zI7t27VytWrFB4eLhWrFihSZMmacGCBfrf//5ndTQAAABkYJZffis+Pl5FihRRkSJFdOrUKUmSv7+/jhw5YnEyAAAAZGSWF1kvLy9dvnxZOXPm1G+//aZ79+4pISFBkZGRVkcDAABABmb51IJmzZqpffv2Wrt2rWrXrq33339fmTJlUunSpa2OBgAAgAzM8iLbtWtXvfDCC3J3d9ewYcM0YcIE3b17V8OGDbM6GgAAADIwy4usJDVq1Mj286hRoyxMAgAAAFNYXmTDwsI0e/ZsXbx40XYd2URLliyxKBUAAAAyOsuL7ODBg3Xz5k3VqVNHLi4uVscBAACAISwvssePH9cXX3yhnDlzWh0FAAAABrH88lvu7u5ydXW1OgYAAAAMY/mIbI8ePTR48GC99957ypUrl91z+fLlsygVAAAAMjrLi+zQoUMlSf/973/tljs4ONju9AUAAAD8keVFdteuXVZHAAAAgIEsK7J+fn5ycHCwW5YpUybly5dPbdq0sbu2LAAAAPBHlhXZXr16JVkWGxurS5cuafTo0YqLi1PTpk0tSAYAAAATWFZkW7VqleJzlStX1rRp0yiyAAAASJHll99KTtWqVXXx4kWrYwAAACADy5BF1sXFJcn8WQAAAOBRGbLI7t+/XwUKFLA6BgAAADIwy+bIbty4Mcmy2NhYXb16VStWrNCAAQOefSgAAAAYw7IiO3369CTLMmXKpLx582rQoEFq2bLlsw8FAAAAY1hWZHfv3m3VrgEAAPA3kCHnyAIAAACPQ5EFAACAkSiyAAAAMBJFFgAAAEaiyAIAAMBIFFkAAAAYiSILAAAAI1FkAQAAYCSKLAAAAIxEkQUAAICRKLIAAAAwEkUWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjUWQBAABgJIosAAAAjESRBQAAgJEosgAAADASRRYAAABGosgCAADASBRZAAAAGIkiCwAAACNRZAEAAGAkiiwAAACMRJEFAACAkSiyAAAAMBJFFgAAAEaiyAIAAMBIFFkAAAAYiSILAAAAI1FkAQAAYCSKLAAAAIxEkQUAAICRKLIAAAAwEkUWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjUWQBAABgJIosAAAAjESRBQAAgJEosgAAADASRRYAAABGosgCAADASBRZAAAAGIkiCwAAACNRZAEAAGAkiiwAAACMRJEFAACAkSiyAAAAMBJFFgAAAEaiyAIAAMBIFFkAAAAYiSILAAAAI1FkAQAAYCSKLAAAAIxEkQUAAICRKLIAAAAwEkUWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjOadmpZkzZ6Z6gz179nziMAAAAEBqparIrl+/PlUbc3BwoMgCAADgmUhVkd29e/fTzgEAAACkSbrNkY2OjtaRI0fSa3MAAADAn0rViOyjTp48qaFDh+rMmTOKj49P8vypU6fSJRgAAADwZ9I8IhscHCxnZ2eNGDFCLi4uGjZsmN555x05Oztr8uTJTyMjAAAAkESaR2RPnDihxYsXq2zZslq3bp2KFSum9u3by8vLS6tXr1ajRo2eRk4AAADATppHZOPj45U7d25JUuHChRUSEiJJqlu3rk6fPp2+6QAAAIAUpLnIFilSRIcPH5YkFSxYUMePH5ck3blzR9HR0embDgAAAEhBmqcWvP322/roo48kSa+99ppatGihzJkz6/vvv1f58uXTOx8AAACQrDQX2TZt2ihHjhzy8PBQ0aJFNX78eM2ZM0d58+bVsGHDnkZGAAAAIIk0F1lJqlevnu3nJk2aqEmTJukWCAAAAEiNNBfZmTNn/unz3KIWAAAAz0Kai+z69evtHsfGxio8PFwuLi6qUKFCugUDAAAA/kyai+zu3buTLLt7964GDRokHx+fdAkFAAAAPE6aL7+VnGzZsqlPnz5auHBhemwOAAAAeKx0KbLS/00xAAAAAJ6FNE8t2Lhxo93jhIQE3blzR6tWrWKOLAAAAJ6ZNBfZwMDApBtxdlbFihU1fPjwdAkFAAAAPE6ai+zp06efRg4AAAAgTdJcZDt06KBPPvlE7u7udst/++03denSJcnUg2cp4JWClu0bAJ6V3lmyWx0BADKEVBXZr7/+WsePH5ckHTp0SLNnz5abm5vdOr/88otCQ0PTPyEAAACQjFQVWW9vb40ePVoJCQlycHDQtm3b5Oj4fxc8cHBwkJubmz788MOnFhQAAAB4VKqK7Isvvqhdu3ZJkvz8/LRu3Tp5eno+1WAAAADAn0nzdWR3796t06dP69tvv7UtGzt2rA4fPpyuwQAAAIA/k+Yiu3nzZr333nv6+eefbcvCwsLUqVMnffnll+kaDgAAAEiJQ0JCQkJaXtCkSRP5+/urffv2dsuXLVum1atXa9OmTekaMC3ux1q2awB4ZjxrDrE6AgA8VVHfBaVqvTSPyF65ckWvvvpqkuU1a9bUxYsX07o5AAAA4ImkucjmzZtXBw8eTLL8+++/V+7cudMlFAAAAPA4ab4hgr+/v8aOHavLly+rXLlycnBw0PHjx7Vo0SL17NnzaWQEAAAAkkhzkQ0ICFB0dLQWL16sOXPmSJKef/55DRgwQC1atEj3gAAAAEBy0nyy16MiIiLk4uKiS5cuacWKFdq6dau+//779MyXJpzsBeCfgJO9APzdpfZkrzSPyCZ68OCBvvrqK61cuVLHjx+Xo6Oj6tev/6SbAwAAANIkzUX2/PnzWrlypTZt2qTbt2/LwcFBbdq0Uffu3ZU/f/6nkREAAABIIlVFNjY2Vjt37tTKlSt1+PBhubi4qFatWmrUqJE+/PBDdezYkRILAACAZypVRbZ27dq6e/euqlatquDgYNWrV0/ZsmWTJA0cOPCpBgQAAACSk6rryN65c0c5c+aUl5eXsmbNKhcXl6edCwAAAPhTqRqR3bdvn7Zt26Z169Zp5cqVcnNzk5+fnxo1aiQHB4ennREAAABIIs2X3zp37pzWrl2rLVu26ObNm7aTvd59910VKlToKcVMHS6/BeCfgMtvAfi7S+3lt574OrJxcXHas2ePNmzYoD179ig+Pl6+vr767LPPnmRz6YIiC+CfgCIL4O/uqV9H1snJSXXr1lXdunUVHh6uTZs2af369U+6OQAAACBN/tKdvTIaRmQB/BMwIgvg7y61I7KpumoBAAAAkNFQZAEAAGAkiiwAAACMRJEFAACAkSiyAAAAMBJFFgAAAEaiyAIAAMBIFFkAAAAYiSILAAAAI1FkAQAAYCSKLAAAAIxEkQUAAICRKLIAAAAwEkUWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjUWQBAABgJIosAAAAjESRBQAAgJEosgAAADASRRYAAABGosgCAADASBRZAAAAGIkiCwAAACNRZAEAAGAkiiwAAACMRJEFAACAkSiyAAAAMBJFFgAAAEaiyAIAAMBIFFkAAAAYiSILAAAAI1FkAQAAYCSKLAAAAIxEkQUAAICRKLIAAAAwEkUWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjUWQBAABgJIosAAAAjESRBQAAgJEosgAAADASRRYAAABGosgCAADASBRZAAAAGIkiCwAAACNRZAEAAGAkiiwAAACMRJEFAACAkSiyAAAAMBJFFgAAAEaiyAIAAMBIFFkAAAAYiSILAAAAI1FkAQAAYCSKLAAAAIxEkQUAAICRKLIAAAAwEkUWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjUWQBAABgJIosAAAAjESRBQAAgJEosgAAADASRRYAAABGosgCAADASJYW2Rs3bigoKEiSdOTIEVWrVk1NmjTR2bNnrYwFAAAAA1haZEePHq1z584pISFBQUFBatKkifz8/DRmzBgrYwEAAMAAzlbu/Pjx49q2bZtu3LihU6dOaf78+XJ3d5ePj4+VsQAAAGAAS0dko6KilDlzZu3fv1/FihWTp6en7t+/L2dnS/s1AAAADGBpYyxbtqxGjhypo0ePqlGjRrp586ZGjx6tKlWqWBkLAAAABrB0RHbs2LGKjo5WpUqV1K1bN4WGhio6OlojRoywMhYAAAAM4JCQkJBgdYj0cj/W6gQA8PR51hxidQQAeKqivgtK1XqWTi0YPHhwis8FBwc/wyQAAAAwTYa6IUJERIS2b98uNzc3q6MAAAAgg7N0RDa5UdfvvvtOy5cvtyANAAAATJKhRmQlydfXVwcOHLA6BgAAADK4DHXB1tjYWH3++efKmTOn1VEAAACQwVlaZF9++WU5ODjYLXNyctJHH31kUSIAAACYwtIiu2TJErvHjo6OKliwoHLnzm1RIgAAAJjC0jmyVapUUaVKlZQ5c2bdvHlTkvTcc89ZGQkAAACGsHRE9saNG+revbtOnz4tDw8PRUREqFChQlqwYIG8vLysjAYAAIAMztIR2fHjx6tQoUI6dOiQ9u3bp4MHD6pEiRLcDAEAAACPZemI7IEDB7Rjxw5lzZpVkuTu7q6RI0eqbt26VsYCAACAASwdkY2Pj09y1QIHBwe5uLhYlAgAAACmsLTI+vj4aOTIkbp3754kKTIyUiNHjlSVKlWsjAUAAAADWDq1YODAgerUqZOqVKkiDw8P3bp1Sy+++KLmzJljZSwAAAAYwNIimy9fPm3dulWHDx9WeHi4vL29VaZMGTk5OVkZCwAAAAawtMhevXpVklSwYEEVLFhQkhQWFibpYckFAAAAUmJpkfXz80tysleiU6dOPeM0AAAAMImlRXbXrl12j8PDw/XZZ59x+S0AAAA8lkNCQkKC1SEedefOHbVq1Upffvllml97P/YpBAKADMaz5hCrIwDAUxX1XVCq1rP08lsp+f33362OAAAAgAzO0qkFM2fOtHscExOjvXv3qnz58tYEAgAAgDEsLbIHDx60e+zk5KQKFSqoW7duFiUCUmfH9m0aMuhfcnXNZFvmV6+egsZNsDAVAPw1tV4pojHdG6h4ody6dz9GG3af0JBPtut+dKwql8yvSf2aqUTh53XzVqTGLfpKiz8/anVk/MNZWmSXLl1q5e6BJ/bTieNq0qyFxowNtjoKAKSLXB5ZtWHiO+o9YZOWbT+mPDmzacvUTvpXQC3NXL1PGyZ11Jh5X+qzTYdUo3whrR73tn46F6Yjp65YHR3/YBlqakEiV1dXeXp6ytfXV97e3s84FfB4P504rtcaNLI6BgCkm5u3IlWgyVjdvRctScqZw02ZXZ1181akWtYurfDb9zRn/QFJ0tdHz2vlFz+qW5uqOvLxWitj4x/O0iIbEhKinTt3qkyZMnrhhRd09epV/fDDDypTpozi4uI0duxYzZ49W9WqVbMyJmAnPj5ep07+pCxZsmjRgs8UFx+nV1+tpb79/6XsOXJYHQ8AnlhiiT27cZC8n8+hb3+4oCVbj2pk1/r66dyvduuevnhd7zR9xYqYgI2lVy1wdnbW8OHDtWbNGk2ePFkrV67U2LFjVbhwYa1fv15BQUGaPHmylRGBJCLCw/VyiZKq91oDbdiyTUv+s1K//HJRQwIHWh0NANJF6TcnqUjzYMXFJWj52PbK5pZJkfej7da5dz9a2dwypbAF4NmwtMh+9913atu2rd2yli1b6uuvv5YkNWrUSOfPn7ciGpCi53Ll0sIly9Sq9evKkiWL8ubLp34DBurbvd8oMvKu1fEA4C+7Hx2razfvaOisHWpQrbju3Y+RW2ZXu3XcMrvqzr0HFiUEHrK0yLq5uenEiRN2y06ePClX14d/WX777TdlyZLFimhAikLOnNbUyRP16L1EoqOj5ejoKBcX1z95JQBkXFVLF9APK/rJxdnJtiyTq7MeRMfq1IXrKlH4ebv1Xy70vE6eD3vWMQE7lhbZjh07qmvXrpoyZYpWr16tKVOmqFu3burYsaOuXr2qzp07q0mTJlZGBJLIkcNDK5cv06IFnyk2NlbXrl7VlEkT1LxlK9t/wgDANMfP/Sq3TC76uEcDuTg7qYCXh4J7NtKiz49ow1fHlSenu3q+6StnJ0fVrFhE7RqU4/JbsJzlt6jdunWr1q1bp2vXrilfvnxq27atXnvtNZ0+fVoHDhxQQECAnJycHr8hcYtaPDtHDh/S9KmTdfbnELlmyqSGjZqo34CBypSJ+WJ4+rhFLZ6Wlws9rwl9m+iVl/Pr98j7WvHFDwpeuFvRMXGq+LK3JvZtqlJF8+jmrUgFL/xK/9n2vdWR8TeV2lvUWl5k0xNFFsA/AUUWwN9daousJZffGjlypEaOHKnBgwenuE5wMBeaBwAAQMosmSP7NxoEBgAAgEWYWgAAhmFqAYC/uww9teBRmzdv1qZNm3T9+nV5e3vrrbfeUq1atayOBQAAgAzO0stvzZ8/X0FBQSpdurT8/f1VpEgRDRw4UOvWrbMyFgAAAAxg6YjsqlWrNH/+fJUqVcq2rH79+goMDFSbNm0sTAYAAICMztIR2cjISBUrVsxuWalSpXTjxg2LEgEAAMAUlhbZ5s2ba8aMGXZXMViwYIEaN25sYSoAAACYwJKpBX5+fnJwcFBsbKzCwsK0du1aeXl56caNG7px44ZefvllK2IBAADAIJYU2V69elmxWwAAAPyNWFJkW7VqZcVuAQAA8Ddi6VULjh8/rkmTJik0NFTx8fF2z+3atcuiVAAAADCBpUV28ODBeumll9SsWTM5Olp63hkAAAAMY2mRDQ0N1YYNG+Ti4mJlDAAAABjI0mHQypUr69SpU1ZGAAAAgKEsHZHt27evOnToIB8fH2XPnt3uueDgYItSAQAAwASWjsiOHTtWzz33nLJmzWplDAAAABjI0hHZn376Sfv27aPIAgAAIM0sHZEtWLCgIiMjrYwAAAAAQ1k6ItuqVSt17txZbdq0kYeHhxwcHGzPtWzZ0rpgAAAAyPAcEhISEqzauZ+fX7LLIyIidOzYsTRv737sX00EABmfZ80hVkcAgKcq6rugVK1n6Yjs7t277R6fP39eixYt0ubNmy1KBAAAAFNYWmQTHTlyRPPnz9fXX3+tYsWKaeDAgVZHAgAAQAZnWZGNj4/Xjh07tHDhQv3888+KjY3VnDlz9Oqrr1oVCQAAAAax5KoFixcvVv369TVhwgTVr19fe/bsUbZs2VSsWDEr4gAAAMBAlozIBgcHq3379goMDJSrq6sVEQAAAGA4S0Zkhw0bpoMHD6pWrVqaMmWKwsLC7C69BQAAADyOJUXW399fW7du1eTJk3X27FnVr19fv//+u/bv36+4uDgrIgEAAMAwll5HNlFoaKiWL1+udevWydHRUc2bN1dgYGCat8N1ZAH8E3AdWQB/d6m9jqylt6hN5O3trYEDB+qbb75R//79dejQIasjAQAAIIPLECOy6YURWQD/BIzIAvi7M2pEFgAAAEgriiwAAACMRJEFAACAkSiyAAAAMBJFFgAAAEaiyAIAAMBIFFkAAAAYiSILAAAAI1FkAQAAYCSKLAAAAIxEkQUAAICRKLIAAAAwEkUWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjUWQBAABgJIosAAAAjESRBQAAgJEosgAAADASRRYAAABGosgCAADASBRZAAAAGIkiCwAAACNRZAEAAGAkiiwAAACMRJEFAACAkSiyAAAAMBJFFgAAAEaiyAIAAMBIFFkAAAAYiSILAAAAI1FkAQAAYCSKLAAAAIxEkQUAAICRKLIAAAAwEkUWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjUWQBAABgJIosAAAAjESRBQAAgJEosgAAADASRRYAAABGosgCAADASBRZAAAAGIkiCwAAACNRZAEAAGAkiiwAAACMRJEFAACAkSiyAAAAMBJFFgAAAEaiyAIAAMBIFFkAAAAYiSILAAAAI1FkAQAAYCSKLAAAAIxEkQUAAICRKLIAAAAwEkUWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjUWQBAABgJIosAAAAjESRBQAAgJEosgAAADASRRYAAABGosgCAADASBRZAAAAGIkiCwAAACNRZAEAAGAkiiwAAACMRJEFAACAkSiyAAAAMBJFFgAAAEaiyAIAAMBIFFkAAAAYiSILAAAAI1FkAQAAYCSKLAAAAIxEkQUAAICRKLIAAAAwEkUWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjUWQBAABgJIosAAAAjESRBQAAgJEosgAAADCSQ0JCQoLVIQAAAIC0YkQWAAAARqLIAgAAwEgUWQAAABiJIgsAAAAjUWQBAABgJIosAAAAjESRBQAAgJEosgAAADASRRYZlp+fn9avX59k+fr16+Xn5/dMs1y5ckXFixfXlStXkn1+8+bNatKkyTPNBOCfZdmyZSpevLgWLVr0xNt43Ofn8OHDNXz48CfePvCsOVsdAPg7aN68uZo3b251DAB/Y8uWLdNbb72lJUuW6O2335azc/r/Ez569Oh03ybwNDEiC2MljpKuWbNGfn5+euWVV9SpUyf9+uuvkqSEhATNnTtXzZo1U6VKlVS5cmUNGDBA9+/flyQFBgZq9OjR6tatmypUqKD69etr//79GjNmjCpXrqzq1atrzZo1dvvcuHGj6tWrJ19fXw0dOlR3796VlHSU47vvvlPLli1VsWJFtWvXThMmTFBAQIAkacaMGbafEz06+nz//n39+9//Vq1atVS5cmUFBATof//7n23d4sWL6+DBg7bHj+47NjZWI0eOVPXq1eXj46P27dvr6NGj6XK8AVhn//79+u233xQYGKj4+Hh98cUXtuf8/Py0cOFCNW/eXOXKldNbb72ln376Se+9954qVKigxo0b232GxMbGavz48fL19VW9evX02WefKfFu9YGBgQoMDLStu2TJEtWpU0c+Pj7q16+fevXqpRkzZkiSAgICbD9LSb+5Cg0NVd++fVWtWjVVr15dAwYM0PXr1yVJBw8eVPHixe3e46P7DgsL07vvvqsqVaqoZs2a6tmzp+21wKMosjDenj17tHHjRn3xxRe6efOmZs2aJUnavn27lixZohkzZujIkSNauXKlvv32W23ZssX22nXr1um9997T0aNHVbZsWXXp0kWFChXS/v371a1bN40ePVrR0dG29Y8cOaLVq1dr8+bNCgkJUVBQUJI8V65cUffu3fXWW2/p0KFD+te//qVVq1al+v2MHDlS3377rZYsWaJ9+/apXr166tixo65evfrY127atEnHjh3T9u3b9d1336ly5coaNWpUqvcNIGNaunSp3nzzTWXOnFnt27fXggUL7J5fs2aN5s6dq3379ik8PFwBAQHq0aOHDh48qGLFimnixIm2dcPCwuTo6Kg9e/Zo6tSpmjdvnjZt2pRkn1u3btXMmTM1adIkffvtt6pUqZJ27tyZqrwxMTHq3LmznJyctHPnTm3fvl2S1L17d8XGxj729ZMnT5aXl5f27dunbdu26d69e5o7d26q9o1/FoosjPfee+8pe/bsypUrl/z8/HTx4kVJUs2aNbV27VoVKlRI4eHhioiIkIeHh8LCwmyvrVq1qipVqiRHR0dVrVpVbm5uCggIkLOzs+rUqaPo6GjdvHnTtn5gYKBy5sypXLlyqXfv3tqyZYvi4+Pt8mzZskUlSpRQ27Zt5ezsrEqVKunNN99M1Xt58OCBPv/8cw0YMEAFCxaUq6ur3nnnHRUpUkSff/75Y1+fOXNmXblyRWvXrtWFCxfUp08fbd68OVX7BpAxhYaGau/evfL395ckvfnmmzp79qwOHTpkW6dNmzby8vJStmzZVLZsWfn4+KhChQpydXVVjRo1FBoaalvX09NT/fv3l6urq0qXLq22bdsm+zmxdu1atW3bVhUrVpSLi4v8/f1VpkyZVGU+cuSILl++rFGjRsnd3V3Zs2fXqFGjdPr0aZ04ceKxr8+UKZOOHj2qrVu3KjIyUp999pmGDh2aqn3jn4UiiwzL1dVVcXFxSZbHxcXJ1dXV9jhXrly2n52dnW1fkSUkJGjKlCmqUqWK2rdvr2XLlikmJsb2vCR5eHjYfnZyclL27Nltjx0cHCTJrqjmz5/f9nPevHkVHR2tW7du2eW7du2avL297Za98MILqXnLun37tmJiYuz2k7jflE40e1STJk00bNgw7dq1Sy1btlSdOnW0YsWKVO0bQMa0fPlyxcbGqkWLFvLx8VGDBg0UGxtrNyr7x8+yHDly2B47Ojrafe7lzZtXTk5Odo8f/Q9+or/yWfbbb7/J09NT2bJlsy3Lli2bPDw87Ep1SoYOHarGjRtr/vz5qlWrllq3bq0jR46kat/4Z+FkL2RYefPmTfYD75dffkny4ZqciRMn6urVq9q9e7ftw7RZs2Z26ySW1dQKCwuzbevKlStyc3NTzpw57dbx9vbWV199Zbfs0WkBjo6OiomJsT2Oj4+3leFcuXIpU6ZMunz5sooWLWpb59KlS7Z5sH98fUREhO3nCxcuqFSpUmrZsqXu37+vHTt2aNCgQapUqZJeeumlNL1XANZ78OCB1q5dq7Fjx8rX19e2PCQkRF27dtW5c+ckpe2z7MaNG0pISLC95vLly8l+pnp7eyeZ0nT16lUVKVJE0p9/Fnl7eysiIkJ37961fWbeuXNHERERyp07txwdH46jRUdH2wYmIiIi5OnpKUk6efKk2rZtq169eik8PFyffPKJevbsqQMHDqT6feKfgRFZZFgtWrTQihUrtG/fPsXHxys6OlrffPON1qxZo9atWz/29Xfv3lWmTJnk5OSkBw8eaMGCBQoJCbH74E2rCRMm6Pbt2/r11181bdo0tW3bNtncp06d0saNGxUXF6cff/xRq1evtj1ftGhRnTlzRj///LNiY2P12Wef6d69e5Ie/sPQpk0bTZ48Wb/88ouio6O1ePFinT171nZ5r6JFi+qLL75QbGysLl26pLVr19q2/dVXX6lnz566cuWKMmfOLA8PDzk7O8vd3f2J3zMA62zZskUODg5q1qyZvLy8bL9q1qypYsWKPdGluG7cuKHZs2crOjpax44d05o1a9SuXbsk67355ptavXq1/ve//yk2Nlbr1q3TDz/8YHu+aNGi2rt3r37//XfduXNH8+bNsz1XpkwZvfjiixoxYoTu3LmjO3fuaOTIkSpQoIAqVqyoAgUKyNnZWVu3bpX08ATZR0vqp59+qjFjxuju3bvKnj27smTJYiu5wKMYkUWG1bJlS8XExGjixIm6dOmS4uPjVbhwYQ0ZMkRNmjR57Fftffv21eDBg+Xr6ys3Nze98soratGihUJCQp44U4UKFdSwYUM5OjqqadOm6tevX5J1vLy8NH36dP373//WqFGjVKJECdWoUcM2WlGvXj1999136tixo+Lj49WyZUu98sorttd/+OGHmjFjhjp27Khbt26pePHimj9/vgoXLixJGjFihIKDg1WlShUVKlRIr7/+upYtWyZJ6tChg8LCwtSuXTvdvXtX3t7emjJliry8vJ74PQOwzvLly9WsWTO5uLgkea5t27YaP358mr9ZSryygI+Pj3Lnzq0PP/ww2WvLNmjQQJcuXVKPHj0UHR2tmjVrqnTp0rYs3bp100cffaS6devK3d1dvXv3tl1NwdnZWXPmzNG4cePUoEEDRUdHy9fXVwsXLpSzs7Oef/55DRkyRLNmzdKYMWNUtWpVtW7dWlFRUZIeXgZs1KhRqlu3rqKjo1W6dGlNmzYtrYcP/wAOCY9OnAHwl127dk0REREqWbKkbdm4ceN048YNTZo0ycJkAJB6p0+flru7u920g9atW6tdu3apPoEVeNqYWgCks4iICLVv3952Zu7p06e1efNm1alTx+JkAJB6Bw4cUPfu3W1zardt26azZ8+qWrVqVkcDbBiRBZ6CNWvWaN68ebpx44Zy5colf39/dezY0epYAJBqiTdO2L59uyIjI1WkSBH1799f1atXtzoaYEORBQAAgJGYWgAAAAAjUWQBAABgJIosAAAAjESRBQAAgJEosgAAADASRRYAnoCfn5+KFy9u+1WiRAlVqlRJAQEBOnLkSLru6+DBg7a7MUlSQECAAgMDU/Xae/fu2e789qSuXLmi4sWL6+DBg39pOwCQ3rhFLQA8oc6dO6tz586SpISEBN26dUuTJ0/Wu+++qx07djy1WwPPmDFDTk5OqVp3wYIFWr9+vfz9/Z9KFgCwEiOyAPCE3NzclDt3buXOnVvPP/+8ihUrplGjRikqKko7d+58avv18PCQu7t7qtblUuEA/s4osgCQjpydH37R5erqKj8/PwUFBalx48by8fHRgQMHlJCQoHnz5qlu3boqV66cWrRooc2bN9tt48iRI3rjjTdUtmxZtWzZUmfOnLF7/o9TC06cOKFOnTqpQoUK8vX11fDhw3Xv3j3NmDFDM2fOVGhoqN3UhHXr1qlRo0YqW7asGjVqpMWLFys+Pt62vZCQEHXo0EHly5dXgwYNdODAgad1uADgL2FqAQCkk7CwMAUFBcnNzU01a9bU3LlztWLFCs2ZM0fu7u4qXry4pkyZoi1btmj48OEqWrSoDh8+rJEjR+rOnTvy9/fX5cuX1blzZ7Vs2VLjxo3T2bNnNXz48BT3eeXKFQUEBMjPz0+rVq3S3bt3NXjwYA0fPlyjRo3SvXv3tG3bNq1du1Y5c+bUqlWrNGnSJA0fPlzlypXTyZMnNWbMGIWFhenDDz/UnTt31LFjR5UvX15r1qzR9evXNWzYsGd4FAEg9SiyAPCE5syZowULFkh6eF/66OhoFS1aVFOnTlW+fPkkSbVq1ZKvr6+khydeLVq0SP/+979Vp04dSVKBAgUUGhqq+fPny9/fX6tXr1auXLk0YsQIOTk5qWjRorp27ZqCg4OTzbB69WrlyJFD48aNk4uLiyTp448/1qFDh5Q1a1a5ubnJyclJuXPnliTNmjVL3bp1U9OmTSVJL7zwgu7evatRo0apT58+2rp1q6KiojR+/Hi5u7vrpZde0pAhQ/TBBx88vQMJAE+IIgsAT6hdu3YKCAiQJDk6OiY7d7VgwYK2n8+ePasHDx5o0KBBGjx4sG15Ygm+f/++QkJCVLJkSbuTuSpWrJhihjNnzqhUqVK2EitJlStXVuXKlZOsGx4erl9//VXTpk3TzJkzbcvj4+P14MEDXblyRSEhISpUqJDd+6hQoUJqDgcAPHMUWQB4Qjly5LArqsnJnDmz7efEE6+mTp2qIkWKJFnX1dXVbr1EifNuk+Ps7CwHB4dU5U2cBzt48GDbKPGj8ubNm+b9A4CVONkLAJ6RIkWKyNnZWVevXlXBggVtv77++mvNnz9fjo6OKlGihI4fP67o6Gjb644fP57iNl988UWdPHlScXFxtmX//e9/VbNmTUVFRdmV3Oeee07PPfecLl26ZLf/n376SVOnTpUklShRQhcuXFB4eHiq9g8AVqLIAsAz4u7urnbt2mnq1KnauHGjLl++rA0bNmjChAnKlSuXJOmtt95SVFSUhgwZonPnzumrr76ymwbwR+3bt1dERIRGjBihc+fO6ciRI5o4caKqV6+uLFmyyM3NTbdv39aFCxcUGxurd999V0uXLtXSpUt16dIlffnllxo1apRcXV3l6uqqJk2a6LnnntOAAQN0+vRpHTp0SEFBQc/qEAFAmvB9EQA8Q4MHD1bOnDk1ffp0Xb9+XV5eXurZs6e6du0qScqTJ48WL16soKAgtWrVSnnz5tX777+vUaNGJbu9PHnyaMGCBZo4caJatWql7Nmzq3Hjxurfv78k6bXXXtPq1avVvHlz/ec//1Hnzp2VKVMmLV26VOPHj9dzzz2n1q1bq1+/fpIeXht3yZIlGj16tN566y3lyJFDffr0SfWdxADgWXJI4GrZAAAAMBBTCwAAAGAkiiwAAACMRJEFAACAkSiyAAAAMBJFFgAAAEaiyAIAAMBIFFkAAAAYiSILAAAAI1FkAQAAYCSKLAAAAIxEkQUAAICRKLIAAAAw0v8DAu2pfAy+TTAAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 700x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CLASSIFICATION REPORT  (Balanced & Tuned)\n",
      "============================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Unambiguous     0.7500    0.3261    0.4545        46\n",
      "   Ambiguous     0.4918    0.8571    0.6250        35\n",
      "\n",
      "    accuracy                         0.5556        81\n",
      "   macro avg     0.6209    0.5916    0.5398        81\n",
      "weighted avg     0.6384    0.5556    0.5282        81\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Few-shot pipeline for anaphora ambiguity detection using candidate counting with softmax thresholding\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import spacy\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, precision_recall_curve,\n",
    "                             precision_recall_fscore_support, accuracy_score, f1_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -------------------------\n",
    "# Config\n",
    "# -------------------------\n",
    "MODEL_NAME = \"mrm8488/spanbert-finetuned-squadv2\"\n",
    "SPACY_MODEL = \"en_core_web_sm\"\n",
    "\n",
    "DATA_PATH = \"anaphoric_ambiguity_spanbert_input_new.csv\"\n",
    "BATCH_SIZE = 8\n",
    "MAX_LENGTH = 512\n",
    "VAL_SET_SIZE = 0.2\n",
    "TEST_SET_SIZE = 0.3\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "WINDOW_CHAR_HALF = 500\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Reproducibility\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# -------------------------\n",
    "# Load spaCy\n",
    "# -------------------------\n",
    "try:\n",
    "    nlp = spacy.load(SPACY_MODEL)\n",
    "except OSError:\n",
    "    print(f\"Spacy model '{SPACY_MODEL}' not found. Downloading...\")\n",
    "    spacy.cli.download(SPACY_MODEL)\n",
    "    nlp = spacy.load(SPACY_MODEL)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Preprocessing\n",
    "# -------------------------\n",
    "# Parse CSV and extract pronoun positions\n",
    "def preprocess_for_evaluation(df):\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PREPROCESSING DATA\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    df['group_id'] = df['Id'].apply(lambda x: '-'.join(str(x).split('-')[:2]))\n",
    "    evaluation_data = []\n",
    "\n",
    "    for group_id, group_df in df.groupby('group_id'):\n",
    "        context_hashed = group_df['Hashed_Context'].iloc[0]\n",
    "        pronoun = group_df['Pronoun'].iloc[0]\n",
    "        is_ambiguous = 0 if group_df['Manual Evaluation'].iloc[0] == 'UA' else 1\n",
    "\n",
    "        pronoun_marker = \"\"\n",
    "        for i in range(10):\n",
    "            marker = f\"{pronoun}#{i}\"\n",
    "            if marker in context_hashed:\n",
    "                pronoun_marker = marker\n",
    "                break\n",
    "\n",
    "        if pronoun_marker:\n",
    "            pronoun_char_start = context_hashed.find(pronoun_marker)\n",
    "            context_clean = context_hashed.replace(pronoun_marker, pronoun)\n",
    "        else:\n",
    "            pronoun_char_start = context_hashed.find(pronoun)\n",
    "            context_clean = context_hashed\n",
    "\n",
    "        if pronoun_char_start != -1:\n",
    "            evaluation_data.append({\n",
    "                'group_id': group_id,\n",
    "                'pronoun': pronoun,\n",
    "                'context_clean': context_clean,\n",
    "                'is_ambiguous_label': is_ambiguous,\n",
    "                'pronoun_char_start': int(pronoun_char_start)\n",
    "            })\n",
    "\n",
    "    eval_df = pd.DataFrame(evaluation_data)\n",
    "    print(f\"Preprocessing complete. Created {len(eval_df)} pronoun instances.\")\n",
    "    if not eval_df.empty:\n",
    "        print(f\"Class distribution:\\n{eval_df['is_ambiguous_label'].value_counts(normalize=True)}\")\n",
    "    return eval_df\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Candidate Extraction\n",
    "# -------------------------\n",
    "# Create candidate spans from NOUN/PROPN tokens with optional left expansion\n",
    "def _pos_based_spans(spacy_doc, max_expansion=2):\n",
    "    spans = []\n",
    "    toks = list(spacy_doc)\n",
    "    \n",
    "    for i, tok in enumerate(toks):\n",
    "        if tok.pos_ in (\"NOUN\", \"PROPN\"):\n",
    "            spans.append((tok.idx, tok.idx + len(tok.text), tok.text))\n",
    "            \n",
    "            start = i\n",
    "            expansion_count = 0\n",
    "            while start > 0 and expansion_count < max_expansion:\n",
    "                prev_tok = toks[start - 1]\n",
    "                if prev_tok.pos_ in (\"DET\", \"ADJ\", \"NUM\"):\n",
    "                    start -= 1\n",
    "                    expansion_count += 1\n",
    "                else:\n",
    "                    break\n",
    "            \n",
    "            if start < i:\n",
    "                span = spacy_doc[start:i+1]\n",
    "                spans.append((span.start_char, span.end_char, span.text))\n",
    "    \n",
    "    return spans\n",
    "\n",
    "# Multi-source candidate extraction\n",
    "def extract_candidates_multi(context_slice, pronoun_rel_char):\n",
    "    doc = nlp(context_slice)\n",
    "    raw_candidates = []\n",
    "\n",
    "    # Noun chunks\n",
    "    for nc in doc.noun_chunks:\n",
    "        if nc.end_char <= pronoun_rel_char:\n",
    "            raw_candidates.append((nc.start_char, nc.end_char, nc.text))\n",
    "\n",
    "    # NER entities\n",
    "    for ent in doc.ents:\n",
    "        if ent.end_char <= pronoun_rel_char:\n",
    "            raw_candidates.append((ent.start_char, ent.end_char, ent.text))\n",
    "\n",
    "    # POS-based spans\n",
    "    for s, e, t in _pos_based_spans(doc, max_expansion=2):\n",
    "        if e <= pronoun_rel_char:\n",
    "            raw_candidates.append((s, e, t))\n",
    "\n",
    "    # Deduplicate\n",
    "    seen = set()\n",
    "    candidates = []\n",
    "    for s, e, t in raw_candidates:\n",
    "        key = (int(s), int(e))\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        candidates.append({'start': int(s), 'end': int(e), 'text': t})\n",
    "\n",
    "    # Fallback: nearest NOUN/PROPN\n",
    "    if not candidates:\n",
    "        nearest = None\n",
    "        min_dist = None\n",
    "        for tok in doc:\n",
    "            if tok.pos_ in (\"NOUN\", \"PROPN\"):\n",
    "                if tok.end_char <= pronoun_rel_char:\n",
    "                    dist = pronoun_rel_char - tok.end_char\n",
    "                    if min_dist is None or dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        nearest = tok\n",
    "        \n",
    "        if nearest is not None:\n",
    "            candidates.append({\n",
    "                'start': int(nearest.idx), \n",
    "                'end': int(nearest.idx + len(nearest.text)), \n",
    "                'text': nearest.text\n",
    "            })\n",
    "        else:\n",
    "            # Extreme fallback: content words only\n",
    "            for tok in reversed(list(doc)):\n",
    "                if tok.end_char <= pronoun_rel_char:\n",
    "                    if tok.pos_ not in (\"DET\", \"ADP\", \"CONJ\", \"CCONJ\", \"SCONJ\", \"PUNCT\", \"SPACE\", \"AUX\"):\n",
    "                        candidates.append({\n",
    "                            'start': int(tok.idx), \n",
    "                            'end': int(tok.idx + len(tok.text)), \n",
    "                            'text': tok.text\n",
    "                        })\n",
    "                        break\n",
    "\n",
    "    return candidates\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Dataset\n",
    "# -------------------------\n",
    "class AnaphoraDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_length=MAX_LENGTH, window_half=WINDOW_CHAR_HALF):\n",
    "        self.data = dataframe.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.window_half = window_half\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        full_context = row['context_clean']\n",
    "        pronoun_abs = int(row['pronoun_char_start'])\n",
    "        pronoun = row['pronoun']\n",
    "\n",
    "        # Centered slice around pronoun\n",
    "        start_char = max(0, pronoun_abs - self.window_half)\n",
    "        end_char = min(len(full_context), pronoun_abs + self.window_half + len(pronoun))\n",
    "        context_slice = full_context[start_char:end_char]\n",
    "        pronoun_rel = pronoun_abs - start_char\n",
    "\n",
    "        question = f\"What is the antecedent of '{pronoun}'?\"\n",
    "\n",
    "        encoding = self.tokenizer(\n",
    "            question,\n",
    "            context_slice,\n",
    "            truncation='only_second',\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_offsets_mapping=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'token_type_ids': encoding['token_type_ids'].squeeze(0),\n",
    "            'offset_mapping': encoding['offset_mapping'].squeeze(0),\n",
    "            'label': torch.tensor(int(row['is_ambiguous_label']), dtype=torch.long),\n",
    "            'context': context_slice,\n",
    "            'pronoun_char_start': torch.tensor(int(pronoun_rel), dtype=torch.long),\n",
    "            'context_offset': torch.tensor(int(start_char), dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Alignment\n",
    "# -------------------------\n",
    "# Align character spans to token indices\n",
    "def align_span_to_token_indices(span_start, span_end, offset_mapping, token_type_ids):\n",
    "    start_idx = None\n",
    "    end_idx = None\n",
    "\n",
    "    if isinstance(offset_mapping, torch.Tensor):\n",
    "        offsets = offset_mapping.cpu().numpy()\n",
    "    else:\n",
    "        offsets = np.asarray(offset_mapping)\n",
    "\n",
    "    token_types = token_type_ids.cpu().numpy() if isinstance(token_type_ids, torch.Tensor) else np.asarray(token_type_ids)\n",
    "\n",
    "    for i, (off, tt) in enumerate(zip(offsets, token_types)):\n",
    "        tok_start, tok_end = int(off[0]), int(off[1])\n",
    "        if int(tt) != 1:\n",
    "            continue\n",
    "        if tok_start == 0 and tok_end == 0:\n",
    "            continue\n",
    "        if start_idx is None and tok_start <= span_start < tok_end:\n",
    "            start_idx = i\n",
    "        if start_idx is not None:\n",
    "            if tok_start < span_end <= tok_end:\n",
    "                end_idx = i\n",
    "                break\n",
    "            elif tok_start < span_end:\n",
    "                end_idx = i\n",
    "    \n",
    "    if start_idx is not None and end_idx is not None and start_idx <= end_idx:\n",
    "        return int(start_idx), int(end_idx)\n",
    "    return None, None\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Feature Extraction\n",
    "# -------------------------\n",
    "def extract_features_from_candidates(model, dataloader, device, verbose=False):\n",
    "    \"\"\"\n",
    "    Extract features from QA model for classification.\n",
    "    \n",
    "    Features:\n",
    "    1. max_prob: highest candidate probability (high = one clear winner)\n",
    "    2. entropy: entropy of distribution (high = ambiguous)\n",
    "    3. num_candidates: total candidates\n",
    "    4. top2_ratio: ratio of 2nd to 1st probability (high = ambiguous)\n",
    "    5. mean_prob: average probability\n",
    "    6. prob_gap: difference between top 2 probabilities (high = unambiguous)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    no_candidates_count = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch in enumerate(tqdm(dataloader, desc=\"Extracting features\", leave=False)):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            token_type_ids = batch['token_type_ids'].to(device)\n",
    "            labels = batch['label']\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, \n",
    "                          token_type_ids=token_type_ids)\n",
    "            start_logits_batch = outputs.start_logits\n",
    "            end_logits_batch = outputs.end_logits\n",
    "\n",
    "            for i in range(len(input_ids)):\n",
    "                context_slice = batch['context'][i]\n",
    "                if isinstance(context_slice, bytes):\n",
    "                    context_slice = context_slice.decode('utf-8')\n",
    "                pronoun_rel = int(batch['pronoun_char_start'][i].item())\n",
    "                offmap = batch['offset_mapping'][i]\n",
    "                tt = batch['token_type_ids'][i]\n",
    "\n",
    "                candidates = extract_candidates_multi(context_slice, pronoun_rel)\n",
    "                candidate_score_tensors = []\n",
    "\n",
    "                if candidates:\n",
    "                    start_logits = start_logits_batch[i]\n",
    "                    end_logits = end_logits_batch[i]\n",
    "                    for cand in candidates:\n",
    "                        s_rel = int(cand['start'])\n",
    "                        e_rel = int(cand['end'])\n",
    "                        start_token_idx, end_token_idx = align_span_to_token_indices(\n",
    "                            s_rel, e_rel, offmap, tt\n",
    "                        )\n",
    "                        if start_token_idx is None or end_token_idx is None:\n",
    "                            continue\n",
    "                        s_logit = start_logits[start_token_idx]\n",
    "                        e_logit = end_logits[end_token_idx]\n",
    "                        span_score = s_logit + e_logit\n",
    "                        candidate_score_tensors.append(span_score)\n",
    "\n",
    "                # Compute features\n",
    "                if not candidate_score_tensors or len(candidate_score_tensors) == 0:\n",
    "                    no_candidates_count += 1\n",
    "                    features = [0.0, 0.0, 0, 0.0, 0.0, 0.0]\n",
    "                else:\n",
    "                    scores_tensor = torch.stack(candidate_score_tensors)\n",
    "                    probs = torch.softmax(scores_tensor, dim=0).cpu().numpy()\n",
    "                    \n",
    "                    # Feature 1: Max probability\n",
    "                    max_prob = float(np.max(probs))\n",
    "                    \n",
    "                    # Feature 2: Entropy (normalized)\n",
    "                    entropy = float(-np.sum(probs * np.log(probs + 1e-10)))\n",
    "                    max_entropy = np.log(len(probs)) if len(probs) > 1 else 1.0\n",
    "                    normalized_entropy = entropy / (max_entropy + 1e-10)\n",
    "                    \n",
    "                    # Feature 3: Number of candidates\n",
    "                    num_candidates = len(probs)\n",
    "                    \n",
    "                    # Feature 4: Top-2 ratio\n",
    "                    sorted_probs = np.sort(probs)[::-1]\n",
    "                    if len(sorted_probs) >= 2:\n",
    "                        top2_ratio = float(sorted_probs[1] / (sorted_probs[0] + 1e-10))\n",
    "                    else:\n",
    "                        top2_ratio = 0.0\n",
    "                    \n",
    "                    # Feature 5: Mean probability\n",
    "                    mean_prob = float(np.mean(probs))\n",
    "                    \n",
    "                    # Feature 6: Probability gap (top1 - top2)\n",
    "                    if len(sorted_probs) >= 2:\n",
    "                        prob_gap = float(sorted_probs[0] - sorted_probs[1])\n",
    "                    else:\n",
    "                        prob_gap = 1.0  # Only one candidate = maximum gap\n",
    "                    \n",
    "                    features = [max_prob, normalized_entropy, num_candidates, top2_ratio, mean_prob, prob_gap]\n",
    "                \n",
    "                # Verbose output for first few examples\n",
    "                if verbose and batch_idx == 0 and i < 3:\n",
    "                    label_i = int(labels[i].item())\n",
    "                    print(f\"\\nExample {i}:\")\n",
    "                    print(f\"  True label: {'Ambiguous' if label_i == 1 else 'Unambiguous'}\")\n",
    "                    print(f\"  Num candidates: {features[2]}\")\n",
    "                    if features[2] > 0:\n",
    "                        print(f\"  Max prob: {features[0]:.3f}\")\n",
    "                        print(f\"  Entropy: {features[1]:.3f}\")\n",
    "                        print(f\"  Top2 ratio: {features[3]:.3f}\")\n",
    "                        print(f\"  Prob gap: {features[5]:.3f}\")\n",
    "                \n",
    "                all_features.append(features)\n",
    "                all_labels.append(int(labels[i].item()))\n",
    "    \n",
    "    if no_candidates_count > 0:\n",
    "        print(f\"  Note: {no_candidates_count} instances had no aligned candidates\")\n",
    "    \n",
    "    return np.array(all_features), np.array(all_labels)\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Few-Shot Classifier\n",
    "# -------------------------\n",
    "def train_few_shot_classifier(train_features, train_labels, val_features, val_labels):\n",
    "    \"\"\"Train a classifier with class weighting and threshold tuning.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING FEW-SHOT CLASSIFIER (WITH BALANCING)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # 1. Use class_weight='balanced' to punish missing Ambiguous cases\n",
    "    classifiers = {\n",
    "        'Logistic Regression': LogisticRegression(\n",
    "            random_state=RANDOM_SEED,\n",
    "            max_iter=1000,\n",
    "            class_weight='balanced'\n",
    "        ),\n",
    "        'Random Forest': RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=RANDOM_SEED,\n",
    "            max_depth=5,\n",
    "            class_weight='balanced'\n",
    "        ),\n",
    "        'SVM (Linear Kernel)': SVC(\n",
    "            kernel='linear',\n",
    "            probability=True,\n",
    "            class_weight='balanced',\n",
    "            random_state=RANDOM_SEED\n",
    "        ),\n",
    "        'Naive Bayes': GaussianNB(),\n",
    "        'KNN (k=5)': KNeighborsClassifier(\n",
    "            n_neighbors=5\n",
    "        ),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=RANDOM_SEED\n",
    "        ),\n",
    "        'AdaBoost': AdaBoostClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=RANDOM_SEED\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    best_clf = None\n",
    "    best_val_f1 = -1\n",
    "    best_threshold = 0.5\n",
    "    best_name = \"\"\n",
    "    \n",
    "    for name, clf in classifiers.items():\n",
    "        # Train\n",
    "        clf.fit(train_features, train_labels)\n",
    "        \n",
    "        # Get probabilities instead of hard predictions\n",
    "        val_probs = clf.predict_proba(val_features)[:, 1]\n",
    "        \n",
    "        # 2. Dynamic Threshold Tuning\n",
    "        precisions, recalls, thresholds = precision_recall_curve(val_labels, val_probs)\n",
    "        \n",
    "        # Calculate F1 for every possible threshold\n",
    "        f1_scores = 2 * (precisions * recalls) / (precisions + recalls + 1e-10)\n",
    "        best_idx = np.argmax(f1_scores)\n",
    "        current_best_thresh = thresholds[best_idx]\n",
    "        current_best_f1 = f1_scores[best_idx]\n",
    "        \n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"  Best Threshold: {current_best_thresh:.3f}\")\n",
    "        print(f\"  Validation F1 (Ambiguous): {current_best_f1:.4f}\")\n",
    "        \n",
    "        if current_best_f1 > best_val_f1:\n",
    "            best_val_f1 = current_best_f1\n",
    "            best_clf = clf\n",
    "            best_threshold = current_best_thresh\n",
    "            best_name = name\n",
    "    \n",
    "    print(f\"\\nSelected Model: {best_name}\")\n",
    "    print(f\"Optimized Threshold: {best_threshold:.3f}\")\n",
    "    \n",
    "    return best_clf, best_threshold\n",
    "\n",
    "# -------------------------\n",
    "# Evaluation\n",
    "# -------------------------\n",
    "def plot_confusion_matrix_and_report(y_true, y_pred, class_names=['Unambiguous', 'Ambiguous'], title_suffix=\"\"):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names, cbar=False)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title(f'Confusion Matrix{title_suffix}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(f\"CLASSIFICATION REPORT {title_suffix}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, digits=4, zero_division=0))\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Main Pipeline\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Using device: {DEVICE}\")\n",
    "    print(f\"Using model: {MODEL_NAME}\")\n",
    "\n",
    "    if not os.path.exists(DATA_PATH):\n",
    "        raise FileNotFoundError(f\"Data file not found at {DATA_PATH}\")\n",
    "\n",
    "    # Load and preprocess data\n",
    "    raw_df = pd.read_csv(DATA_PATH)\n",
    "    eval_df = preprocess_for_evaluation(raw_df)\n",
    "\n",
    "    if eval_df.empty:\n",
    "        raise ValueError(\"No valid pronoun instances found after preprocessing.\")\n",
    "\n",
    "    # Create 3-way split\n",
    "    print(\"\\n\" + \"=\" * 60 + \"\\nSTEP 1: Creating Train/Validation/Test Split\\n\" + \"=\" * 60)\n",
    "    \n",
    "    train_val_df, test_df = train_test_split(\n",
    "        eval_df,\n",
    "        test_size=TEST_SET_SIZE,\n",
    "        random_state=RANDOM_SEED,\n",
    "        stratify=eval_df['is_ambiguous_label']\n",
    "    )\n",
    "\n",
    "    train_df, val_df = train_test_split(\n",
    "        train_val_df,\n",
    "        test_size=VAL_SET_SIZE,\n",
    "        random_state=RANDOM_SEED,\n",
    "        stratify=train_val_df['is_ambiguous_label']\n",
    "    )\n",
    "\n",
    "    print(f\"Train Set Size:      {len(train_df)} ({len(train_df)/len(eval_df)*100:.1f}%)\")\n",
    "    print(f\"Validation Set Size: {len(val_df)} ({len(val_df)/len(eval_df)*100:.1f}%)\")\n",
    "    print(f\"Test Set Size:       {len(test_df)} ({len(test_df)/len(eval_df)*100:.1f}%)\")\n",
    "\n",
    "    # Load model and tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModelForQuestionAnswering.from_pretrained(MODEL_NAME)\n",
    "    model.to(DEVICE)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = AnaphoraDataset(train_df, tokenizer)\n",
    "    val_dataset = AnaphoraDataset(val_df, tokenizer)\n",
    "    test_dataset = AnaphoraDataset(test_df, tokenizer)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    # Extract features\n",
    "    print(\"\\n\" + \"=\" * 60 + \"\\nSTEP 2: Extracting Features for Few-Shot Learning\\n\" + \"=\" * 60)\n",
    "    \n",
    "    print(\"\\nProcessing train set...\")\n",
    "    train_features, train_labels = extract_features_from_candidates(model, train_loader, DEVICE, verbose=True)\n",
    "    \n",
    "    print(\"\\nProcessing validation set...\")\n",
    "    val_features, val_labels = extract_features_from_candidates(model, val_loader, DEVICE)\n",
    "    \n",
    "    print(\"\\nProcessing test set...\")\n",
    "    test_features, test_labels = extract_features_from_candidates(model, test_loader, DEVICE)\n",
    "\n",
    "    # Train few-shot classifier\n",
    "    classifier, optimal_threshold = train_few_shot_classifier(train_features, train_labels, val_features, val_labels)\n",
    "\n",
    "\n",
    "    # Final evaluation\n",
    "    print(\"\\n\" + \"=\" * 60 + \"\\nSTEP 3: Final Test Evaluation (Optimized)\\n\" + \"=\" * 60)\n",
    "    \n",
    "    # Get probabilities for test set\n",
    "    test_probs = classifier.predict_proba(test_features)[:, 1]\n",
    "    \n",
    "    # Apply the learned threshold\n",
    "    test_preds = (test_probs >= optimal_threshold).astype(int)\n",
    "    \n",
    "    plot_confusion_matrix_and_report(test_labels, test_preds, title_suffix=\" (Balanced & Tuned)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1943e211",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
