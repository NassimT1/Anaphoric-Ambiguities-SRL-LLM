{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a23d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: spacy in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 3)) (3.7.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 4)) (3.9.1)\n",
      "Requirement already satisfied: benepar==0.2.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: stanza==1.2 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 6)) (1.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 8)) (1.7.2)\n",
      "Requirement already satisfied: imblearn in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 9)) (0.0)\n",
      "Requirement already satisfied: torch in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 11)) (2.4.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 12)) (4.48.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\nassim\\appdata\\roaming\\python\\python311\\site-packages (from -r requirements.txt (line 13)) (2.19.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 15)) (4.67.1)\n",
      "Requirement already satisfied: pydotplus in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 16)) (2.0.2)\n",
      "Requirement already satisfied: scikit-plot in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 17)) (0.3.7)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from -r requirements.txt (line 18)) (3.7.1)\n",
      "Requirement already satisfied: torch-struct>=0.5 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from benepar==0.2.0->-r requirements.txt (line 5)) (0.5)\n",
      "Requirement already satisfied: tokenizers>=0.9.4 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from benepar==0.2.0->-r requirements.txt (line 5)) (0.21.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from benepar==0.2.0->-r requirements.txt (line 5)) (3.20.3)\n",
      "Requirement already satisfied: sentencepiece>=0.1.91 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from benepar==0.2.0->-r requirements.txt (line 5)) (0.2.0)\n",
      "Requirement already satisfied: requests in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from stanza==1.2->-r requirements.txt (line 6)) (2.32.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from pandas->-r requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (8.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (5.2.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (2.5.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (80.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from spacy->-r requirements.txt (line 3)) (3.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from tqdm->-r requirements.txt (line 15)) (0.4.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 3)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 3)) (2.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 3)) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from requests->stanza==1.2->-r requirements.txt (line 6)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from requests->stanza==1.2->-r requirements.txt (line 6)) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from requests->stanza==1.2->-r requirements.txt (line 6)) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from requests->stanza==1.2->-r requirements.txt (line 6)) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy->-r requirements.txt (line 3)) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy->-r requirements.txt (line 3)) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy->-r requirements.txt (line 3)) (8.1.8)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy->-r requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from nltk->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from nltk->-r requirements.txt (line 4)) (2022.7.9)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 8)) (1.16.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 8)) (3.5.0)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from imblearn->-r requirements.txt (line 9)) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from torch->-r requirements.txt (line 11)) (3.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from torch->-r requirements.txt (line 11)) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from torch->-r requirements.txt (line 11)) (3.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from torch->-r requirements.txt (line 11)) (2025.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 12)) (0.26.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 12)) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from transformers->-r requirements.txt (line 12)) (0.5.2)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\nassim\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow->-r requirements.txt (line 13)) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\nassim\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow->-r requirements.txt (line 13)) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 13)) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\nassim\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow->-r requirements.txt (line 13)) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\nassim\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow->-r requirements.txt (line 13)) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 13)) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 13)) (3.4.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 13)) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 13)) (2.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 13)) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\nassim\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow->-r requirements.txt (line 13)) (1.69.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\nassim\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow->-r requirements.txt (line 13)) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\nassim\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow->-r requirements.txt (line 13)) (3.10.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\nassim\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow->-r requirements.txt (line 13)) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 13)) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from tensorflow->-r requirements.txt (line 13)) (0.31.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow->-r requirements.txt (line 13)) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow->-r requirements.txt (line 13)) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow->-r requirements.txt (line 13)) (2.2.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from pydotplus->-r requirements.txt (line 16)) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 18)) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 18)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 18)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements.txt (line 18)) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\nassim\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib->-r requirements.txt (line 18)) (11.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 13)) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 13)) (13.8.1)\n",
      "Requirement already satisfied: namex in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 13)) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 13)) (0.13.1)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from transformers[tokenizers,torch]>=4.2.2->benepar==0.2.0->-r requirements.txt (line 5)) (0.26.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from accelerate>=0.26.0->transformers[tokenizers,torch]>=4.2.2->benepar==0.2.0->-r requirements.txt (line 5)) (5.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow->-r requirements.txt (line 13)) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 13)) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 13)) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 13)) (0.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nassim\\anaconda3\\lib\\site-packages (from sympy->torch->-r requirements.txt (line 11)) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~aiss-cpu (c:\\Users\\Nassim\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~illow (c:\\Users\\Nassim\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~aiss-cpu (c:\\Users\\Nassim\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~illow (c:\\Users\\Nassim\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~aiss-cpu (c:\\Users\\Nassim\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~illow (c:\\Users\\Nassim\\anaconda3\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76ba80a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nassim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package verbnet to\n",
      "[nltk_data]     C:\\Users\\Nassim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package verbnet is already up-to-date!\n",
      "c:\\Users\\Nassim\\anaconda3\\Lib\\site-packages\\thinc\\shims\\pytorch.py:253: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(filelike, map_location=device))\n",
      "[nltk_data] Downloading package benepar_en3 to\n",
      "[nltk_data]     C:\\Users\\Nassim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package benepar_en3 is already up-to-date!\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 98.0MB/s]                    \n",
      "2025-11-02 12:55:00 INFO: Downloading default packages for language: en (English)...\n",
      "2025-11-02 12:55:00 INFO: File exists: C:\\Users\\Nassim\\stanza_resources\\en\\default.zip.\n",
      "2025-11-02 12:55:02 INFO: Finished downloading models and saved to C:\\Users\\Nassim\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import benepar\n",
    "import stanza\n",
    "\n",
    "nltk.download('wordnet', quiet=False)\n",
    "nltk.download('verbnet', quiet=False)\n",
    "\n",
    "spacy.load('en_core_web_trf')\n",
    "benepar.download('benepar_en3')\n",
    "stanza.download('en', logging_level='INFO')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d515e2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Nassim\\AppData\\Roaming\\Python\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Nassim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package benepar_en3 to\n",
      "[nltk_data]     C:\\Users\\Nassim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package benepar_en3 is already up-to-date!\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 128MB/s]                     \n",
      "2025-11-02 12:55:10 INFO: Downloading default packages for language: en (English)...\n",
      "2025-11-02 12:55:10 INFO: File exists: C:\\Users\\Nassim\\stanza_resources\\en\\default.zip.\n",
      "2025-11-02 12:55:12 INFO: Finished downloading models and saved to C:\\Users\\Nassim\\stanza_resources.\n",
      "[nltk_data] Downloading package verbnet to\n",
      "[nltk_data]     C:\\Users\\Nassim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package verbnet is already up-to-date!\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<benepar.integrations.spacy_plugin.BeneparComponent at 0x22dab71eed0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import benepar\n",
    "from tqdm import tqdm\n",
    "import utils\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "# Pseudocode Step 1: Load spaCy language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "nlp.add_pipe('benepar', config={'model': 'benepar_en3'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b1eb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Initial shape: (159, 10)\n",
      "Cleaned dataset. Shape after removing empty rows: (159, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domain</th>\n",
       "      <th>Raw Requirements</th>\n",
       "      <th>Manual Evaluation</th>\n",
       "      <th>Automated</th>\n",
       "      <th>ChatGPT</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game</td>\n",
       "      <td>The Game must be programmed using the C# langu...</td>\n",
       "      <td>UA</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Game</td>\n",
       "      <td>The User shall be able to the select username ...</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Game</td>\n",
       "      <td>Username and Password must be available to ent...</td>\n",
       "      <td>A</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Game</td>\n",
       "      <td>The website shall enable the players to select...</td>\n",
       "      <td>A</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Game</td>\n",
       "      <td>Each team players will have Names, Contacts nu...</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>UA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Domain                                   Raw Requirements Manual Evaluation  \\\n",
       "0   Game  The Game must be programmed using the C# langu...                UA   \n",
       "1   Game  The User shall be able to the select username ...                UA   \n",
       "2   Game  Username and Password must be available to ent...                 A   \n",
       "3   Game  The website shall enable the players to select...                 A   \n",
       "4   Game  Each team players will have Names, Contacts nu...                UA   \n",
       "\n",
       "  Automated ChatGPT   Unnamed: 5  Unnamed: 6  Unnamed: 7  Unnamed: 8  \\\n",
       "0         A        A         NaN         NaN         NaN         NaN   \n",
       "1        UA       UA         NaN         NaN         NaN         NaN   \n",
       "2        UA       UA         NaN         NaN         NaN         NaN   \n",
       "3        UA       UA         NaN         NaN         NaN         NaN   \n",
       "4        UA       UA         NaN         NaN         NaN         NaN   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                      \n",
       "0                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "1                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "2                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "3                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "4                                                NaN                                                                                                                                                                                                                                                                                                                                                                                                                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 48/159 [00:01<00:03, 31.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As we are working on web-based application with backend in python, so there would be different libraries imported for python and Web App.\n",
      "\n",
      "Each user will have their own\n",
      "User Name\n",
      "Email\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 56/159 [00:01<00:03, 29.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasker can sent video to admin pages after confirmation, it will be added on home page.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 159/159 [00:05<00:00, 28.71it/s]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Anaphoric.csv')\n",
    "\n",
    "# Identify the correct column for requirements\n",
    "requirements_column = 'Raw Requirements'\n",
    "if requirements_column not in df.columns:\n",
    "    requirements_column = df.columns[0]\n",
    "    print(f\"Column 'Requirement' not found. Using the first column: '{requirements_column}'\")\n",
    "\n",
    "print(f\"Dataset loaded. Initial shape: {df.shape}\")\n",
    "\n",
    "# Drop rows where the requirement text is missing (NaN)\n",
    "df.dropna(subset=[requirements_column], inplace=True)\n",
    "\n",
    "# Ensure all data in the column is of string type to prevent errors\n",
    "df[requirements_column] = df[requirements_column].astype(str)\n",
    "\n",
    "print(f\"Cleaned dataset. Shape after removing empty rows: {df.shape}\")\n",
    "display(df.head())\n",
    "\n",
    "# Pseudocode Step 2: Apply NLP to Data\n",
    "df['Context_doc'] = df[requirements_column].progress_apply(lambda text: utils.applynlp(text, nlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657688eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating (Pronoun, Candidate Antecedent) pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Triples: 100%|██████████| 159/159 [00:00<00:00, 14992.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\nGenerated 461 pronoun-antecedent pairs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Context</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Position</th>\n",
       "      <th>Candidate_Antecedent</th>\n",
       "      <th>Manual Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-its-0</td>\n",
       "      <td>(The, Game, must, be, programmed, using, the, ...</td>\n",
       "      <td>its</td>\n",
       "      <td>11</td>\n",
       "      <td>(The, Game)</td>\n",
       "      <td>UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-its-0</td>\n",
       "      <td>(The, Game, must, be, programmed, using, the, ...</td>\n",
       "      <td>its</td>\n",
       "      <td>11</td>\n",
       "      <td>(the, C, #, language)</td>\n",
       "      <td>UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-its-0</td>\n",
       "      <td>(The, Game, must, be, programmed, using, the, ...</td>\n",
       "      <td>its</td>\n",
       "      <td>11</td>\n",
       "      <td>(the, C, #, language, and, its, libraries)</td>\n",
       "      <td>UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-their-0</td>\n",
       "      <td>(The, User, shall, be, able, to, the, select, ...</td>\n",
       "      <td>their</td>\n",
       "      <td>12</td>\n",
       "      <td>(The, User)</td>\n",
       "      <td>UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-their-0</td>\n",
       "      <td>(The, User, shall, be, able, to, the, select, ...</td>\n",
       "      <td>their</td>\n",
       "      <td>12</td>\n",
       "      <td>(the, select, username)</td>\n",
       "      <td>UA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id                                            Context Pronoun  \\\n",
       "0    0-its-0  (The, Game, must, be, programmed, using, the, ...     its   \n",
       "1    0-its-0  (The, Game, must, be, programmed, using, the, ...     its   \n",
       "2    0-its-0  (The, Game, must, be, programmed, using, the, ...     its   \n",
       "3  1-their-0  (The, User, shall, be, able, to, the, select, ...   their   \n",
       "4  1-their-0  (The, User, shall, be, able, to, the, select, ...   their   \n",
       "\n",
       "   Position                        Candidate_Antecedent Manual Evaluation  \n",
       "0        11                                 (The, Game)                UA  \n",
       "1        11                       (the, C, #, language)                UA  \n",
       "2        11  (the, C, #, language, and, its, libraries)                UA  \n",
       "3        12                                 (The, User)                UA  \n",
       "4        12                     (the, select, username)                UA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Pseudocode Step 3: Define Pronouns\n",
    "pronouns_list = [\n",
    "    \"i\", \"me\", \"my\", \"mine\", \"myself\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "    \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\",\n",
    "    \"it\", \"its\", \"itself\", \"we\", \"us\", \"our\", \"ours\", \"ourselves\",\n",
    "    \"they\", \"them\", \"their\", \"theirs\", \"themselves\"\n",
    "]\n",
    "\n",
    "# Pseudocode Step 4: Initialize Data Structures\n",
    "processed_triples = []\n",
    "ids_used = set()  # Use a set for fast checking of uniqueness\n",
    "\n",
    "print(\"Generating (Pronoun, Candidate Antecedent) pairs...\")\n",
    "\n",
    "# Pseudocode Step 6: For each unique context, find pronouns and antecedents\n",
    "for i, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Generating Triples\"):\n",
    "    doc = row['Context_doc']\n",
    "    \n",
    "    if not isinstance(doc, spacy.tokens.Doc):\n",
    "        continue\n",
    "\n",
    "    pronouns_in_doc = utils.findPronouns(doc, pronouns_list)\n",
    "    \n",
    "    for j, pronoun in enumerate(pronouns_in_doc):\n",
    "        # Generate a unique ID for each pronoun-context pair\n",
    "        base_id = f\"{i}-{pronoun.text.lower()}-{j}\"\n",
    "        \n",
    "        # Ensure ID is unique\n",
    "        k = 0\n",
    "        pronoun_id = base_id\n",
    "        while pronoun_id in ids_used:\n",
    "            k += 1\n",
    "            pronoun_id = f\"{base_id}-{k}\"\n",
    "        ids_used.add(pronoun_id)\n",
    "        \n",
    "        candidate_antecedents = utils.getNPs(doc, pronoun)\n",
    "        \n",
    "        for candidate in candidate_antecedents:\n",
    "            # Append data to list\n",
    "            processed_triples.append([\n",
    "                pronoun_id,\n",
    "                doc,\n",
    "                pronoun,\n",
    "                pronoun.i,\n",
    "                candidate,\n",
    "                row['Manual Evaluation']\n",
    "            ])\n",
    "\n",
    "# Pseudocode Step 7: Create DataFrame from Results\n",
    "triples_df = pd.DataFrame(processed_triples, columns=[\n",
    "    \"Id\", \"Context\", \"Pronoun\", \"Position\", \n",
    "    \"Candidate_Antecedent\", \"Manual Evaluation\"\n",
    "])\n",
    "\n",
    "print(f\"Generated {len(triples_df)} pronoun-antecedent pairs.\")\n",
    "display(triples_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af9b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing DataFrame: Creating Hashed Context and serializing data...\n",
      "\\nPreprocessing complete. Data ready for SpanBERT and saved to 'anaphoric_ambiguity_spanbert_input.csv'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Hashed_Context</th>\n",
       "      <th>Pronoun</th>\n",
       "      <th>Position</th>\n",
       "      <th>Candidate_Antecedent</th>\n",
       "      <th>Manual Evaluation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-its-0</td>\n",
       "      <td>The Game must be programmed using the C# langu...</td>\n",
       "      <td>its</td>\n",
       "      <td>11</td>\n",
       "      <td>The Game</td>\n",
       "      <td>UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0-its-0</td>\n",
       "      <td>The Game must be programmed using the C# langu...</td>\n",
       "      <td>its</td>\n",
       "      <td>11</td>\n",
       "      <td>the C# language</td>\n",
       "      <td>UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0-its-0</td>\n",
       "      <td>The Game must be programmed using the C# langu...</td>\n",
       "      <td>its</td>\n",
       "      <td>11</td>\n",
       "      <td>the C# language and its libraries</td>\n",
       "      <td>UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-their-0</td>\n",
       "      <td>The User shall be able to the select username ...</td>\n",
       "      <td>their</td>\n",
       "      <td>12</td>\n",
       "      <td>The User</td>\n",
       "      <td>UA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1-their-0</td>\n",
       "      <td>The User shall be able to the select username ...</td>\n",
       "      <td>their</td>\n",
       "      <td>12</td>\n",
       "      <td>the select username</td>\n",
       "      <td>UA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id                                     Hashed_Context Pronoun  \\\n",
       "0    0-its-0  The Game must be programmed using the C# langu...     its   \n",
       "1    0-its-0  The Game must be programmed using the C# langu...     its   \n",
       "2    0-its-0  The Game must be programmed using the C# langu...     its   \n",
       "3  1-their-0  The User shall be able to the select username ...   their   \n",
       "4  1-their-0  The User shall be able to the select username ...   their   \n",
       "\n",
       "   Position               Candidate_Antecedent Manual Evaluation  \n",
       "0        11                           The Game                UA  \n",
       "1        11                    the C# language                UA  \n",
       "2        11  the C# language and its libraries                UA  \n",
       "3        12                           The User                UA  \n",
       "4        12                the select username                UA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a copy of the original triples DataFrame to avoid modifying it directly\n",
    "final_df = triples_df.copy()\n",
    "\n",
    "# Create a dictionary to store the modified context with hashed pronouns\n",
    "hashed_context_map = {}\n",
    "\n",
    "# Group the DataFrame by pronoun ID to process each pronoun instance separately\n",
    "for pronoun_id, group in final_df.groupby('Id'):\n",
    "    # Take the first row of the group (all rows share the same context and pronoun)\n",
    "    first_row = group.iloc[0]\n",
    "    pronoun_token = first_row['Pronoun']\n",
    "    context_doc = first_row['Context']\n",
    "    \n",
    "    # Create a hashed version of the pronoun using its text and index\n",
    "    hashed_pronoun = f\"{pronoun_token.text}#{pronoun_id.split('-')[-1]}\"\n",
    "\n",
    "    # Replace the original pronoun in the context with the hashed version\n",
    "    hashed_context_map[pronoun_id] = (\n",
    "        context_doc[:pronoun_token.i].text_with_ws + \n",
    "        hashed_pronoun + \n",
    "        context_doc[pronoun_token.i + 1:].text_with_ws\n",
    "    )\n",
    "\n",
    "# Add the new hashed context to the DataFrame\n",
    "final_df['Hashed_Context'] = final_df['Id'].map(hashed_context_map)\n",
    "\n",
    "# Convert spaCy token and span objects to plain text for serialization\n",
    "final_df['Pronoun'] = final_df['Pronoun'].apply(lambda token: token.text)\n",
    "final_df['Candidate_Antecedent'] = final_df['Candidate_Antecedent'].apply(lambda span: span.text)\n",
    "\n",
    "# Remove the original 'Context' column since it's no longer needed\n",
    "final_df.drop(columns=['Context'], inplace=True)\n",
    "\n",
    "# Reorder and select the final columns for SpanBERT input\n",
    "final_df = final_df[[\n",
    "    'Id', 'Hashed_Context', 'Pronoun', 'Position', \n",
    "    'Candidate_Antecedent', 'Manual Evaluation'\n",
    "]]\n",
    "\n",
    "# Save file\n",
    "output_filename = 'anaphoric_ambiguity_spanbert_input.csv'\n",
    "final_df.to_csv(output_filename, index=False)\n",
    "\n",
    "display(final_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
